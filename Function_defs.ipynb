{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a484df80",
   "metadata": {},
   "source": [
    "# All Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49bd146d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_TA(array,freq): #This function converts thermal temp to antenna temp using the standard TA=T*x/(e^x-1) formula\n",
    "    for x in range(len(array)):\n",
    "        if not array[x]<=0 and not array[x]==np.inf:\n",
    "            IGL=(6.62607015*(10**(-34))*freq*(10**6))/(1.380649*(10**(-23))*array[x])\n",
    "            array[x]=(IGL/(np.exp(IGL)-1))*array[x]\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fe6d393",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_TT(temp_array,freq): #This function does the opposite, and converts to thermal temp\n",
    "    \n",
    "    for i in range(len(temp_array)):\n",
    "        TA=temp_array[i]\n",
    "        convert_to_thermal_temp = lambda TT : TA-((6.62607015*(10**(-34))*freq*10**6)/(1.380649*(10**(-23))*TT)/\n",
    "                       (np.exp((6.62607015*(10**(-34))*freq*10**6)/(1.380649*(10**(-23))*TT))-1))*TT \n",
    "        TT_guess = TA\n",
    "        TT = fsolve(convert_to_thermal_temp, TT_guess)\n",
    "        temp_array[i]=TT[0]\n",
    "    return temp_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d701011f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAP_Rotation_to_G(array,coords):\n",
    "    #A rotator function which rotates a map to G. Does a fair amount of smoothing-- avoid if possible\n",
    "    npix=int(np.sqrt(len(array)/12)) #12*Nside^2=total number of pixels\n",
    "    theta1,phi1=hp.pix2ang(npix,np.arange(len(array)))\n",
    "    if coords==\"E\":\n",
    "        r = hp.rotator.Rotator(coord=[\"G\",\"E\"])\n",
    "        theta,phi=(r(theta1,phi1))\n",
    "    if coords==\"C\":\n",
    "        r = hp.rotator.Rotator(coord=[\"G\",\"C\"])\n",
    "        theta,phi=(r(theta1,phi1))\n",
    "    array = hp.get_interp_val(array, theta, phi)\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35580be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TG_calculation(files):\n",
    "    #This function calculates T_g from each method and uses ARCADE's uncertainty as the uncertainty\n",
    "    T_g_array=[]\n",
    "    T_g_unc=[]\n",
    "    for file in tqdm(files):\n",
    "        c_ARCADE,c_unc_ARCADE,T_g_ARCADE,T_g_unc_ARCADE,freq=cscb_Temp_fit_ARCADE(file,\"North\",False)\n",
    "        c_hol,c_unc_hol,T_g_hol,T_g_unc_hol,freq=cscb_Temp_fit_hol(file,\"North\",False)\n",
    "        c_hol_mean,c_unc_hol_mean,T_g_hol_mean,T_g_unc_hol_mean,freq=cscb_Temp_fit_hol_mean(file,\"North\",False)\n",
    "        T_g=np.mean([T_g_ARCADE,T_g_hol,T_g_hol_mean])\n",
    "        T_g_array.append([T_g])\n",
    "        T_g_unc.append([T_g_unc_ARCADE])\n",
    "        c_ARCADE,c_unc_ARCADE,T_g_ARCADE,T_g_unc_ARCADE,freq=cscb_Temp_fit_ARCADE(file,\"South\",False)\n",
    "        c_hol,c_unc_hol,T_g_hol,T_g_unc_hol,freq=cscb_Temp_fit_hol(file,\"South\",False)\n",
    "        c_hol_mean,c_unc_hol_mean,T_g_hol_mean,T_g_unc_hol_mean,freq=cscb_Temp_fit_hol_mean(file,\"South\",False)\n",
    "        T_g=np.mean([T_g_ARCADE,T_g_hol,T_g_hol_mean])\n",
    "        index=files.index(file)\n",
    "        T_g_array[index].append(T_g)\n",
    "        T_g_unc[index].append(T_g_unc_ARCADE)\n",
    "    return T_g_array,T_g_unc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbfd1e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DynestyFit(dim,loglike,ptlist,graph):\n",
    "    #Performs a dynesty fit\n",
    "    #dim=dimension of the problem\n",
    "    #loklike is the likelihood function\n",
    "    #ptlist is a list of length dim, which goes as [max,min] for each parameter involved\n",
    "    #graph is a boolean to determine whether the parameters' are graphed\n",
    "    ndim=dim\n",
    "\n",
    "    def ptform(u):\n",
    "        x = np.array(u)\n",
    "        for i in range(dim):\n",
    "            rang=(ptlist[i][0]-ptlist[i][1])\n",
    "            x[i]=rang*u[i]+ptlist[i][1]\n",
    "        return x\n",
    "    \n",
    "    # \"Static\" nested sampling.\n",
    "    sampler = dynesty.NestedSampler(loglike, ptform, ndim)\n",
    "    sampler.run_nested()\n",
    "    sresults = sampler.results\n",
    "    dsampler = dynesty.DynamicNestedSampler(loglike, ptform, ndim,nlive=500)\n",
    "    dsampler.run_nested()\n",
    "    dresults = dsampler.results\n",
    "    results = dyfunc.merge_runs([sresults, dresults])\n",
    "\n",
    "    if graph==True:\n",
    "        from dynesty import plotting as dyplot\n",
    "        cfig, caxes = dyplot.cornerplot(results,show_titles=True)\n",
    "\n",
    "    samples=results.samples\n",
    "    weights=np.exp(results[\"logwt\"]-results[\"logz\"][-1])\n",
    "    quantiles=[dyfunc.quantile(samps,[0.159,0.5,0.841],weights=weights) for samps in samples.T]\n",
    "    const=[]\n",
    "    const_err=[]\n",
    "    for x in quantiles:\n",
    "        const.append(x[1])\n",
    "        const_err.append((abs(x[1]-x[0])+abs(x[1]-x[2]))/2)\n",
    "    return const,const_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a5b53e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cscb_Temp_fit_ARCADE(file,region,graph):\n",
    "    \n",
    "    #We first convert the array to a list to go faster\n",
    "    if file[1]==1420:#1420 MHz is the only one on this list (so far) that is in mK\n",
    "        File_as_List=(hp.read_map(file[0])/1000).tolist()\n",
    "    else:\n",
    "        File_as_List=(hp.read_map(file[0])).tolist()\n",
    "    \n",
    "    #If we have the uncertainty map, we read it and convert it to a list\n",
    "    if type(file[4])==str:\n",
    "        Unc_as_List=(hp.read_map(file[4])).tolist()\n",
    "    elif type(file[4])==list:\n",
    "        Unc_as_List=(np.sqrt((0.01*file[4][1]*np.array(File_as_List))**2)).tolist()\n",
    "    \n",
    "    #If we start in thermo-temp, we make sure to converto to antenna temp:\n",
    "    if file[3]==True:\n",
    "        convert_to_TA(File_as_List,file[1])\n",
    "        \n",
    "    #Next, we define our theta coords to bin each value by csc|b|, making sure to go to galactic coords\n",
    "    npix=int(np.sqrt(len(File_as_List)/12)) #12*Nside^2=total number of pixels\n",
    "    theta1,phi1=hp.pix2ang(npix,np.arange(len(File_as_List)))\n",
    "    if file[2]==\"E\":\n",
    "        r = hp.rotator.Rotator(coord=['E','G'])\n",
    "        theta=np.degrees(r(theta1,phi1)[0])\n",
    "    if file[2]==\"C\":\n",
    "        r = hp.rotator.Rotator(coord=['C','G'])\n",
    "        theta=np.degrees(r(theta1,phi1)[0])\n",
    "    if file[2]==\"G\":\n",
    "        theta=np.degrees(theta1)\n",
    "    \n",
    "    cscb_Temp_values=[[],[],[],[],[],[],[],[],[],[]] #each entry represents an 0.5 increase from 1.25 (1.25,1.75,2.25...)\n",
    "    unc_Temp_values=[[],[],[],[],[],[],[],[],[],[]]\n",
    "    csc_list=[[],[],[],[],[],[],[],[],[],[]]\n",
    "    #Now, we bin each actual temp (AKA, not inf, negative, or NaN) and its corresponding theta (b or latitude) by csc|b|\n",
    "    for x in (range(int(len(File_as_List)))):\n",
    "        if File_as_List[x]>0 and math.isnan(File_as_List[x])==False and Unc_as_List[x]>=0: #ignore hp.UNSEEN and 0 temp pixels\n",
    "            \n",
    "            #(2326 MHz has an uncertain absolute temp, we correct that)\n",
    "            if file[1]==2326:\n",
    "                File_as_List[x]+=2.505+0.325*(2326/2000)**(-2.75)\n",
    "            \n",
    "            #We then may choose to look at the Northern hemisphere, the Southern one, or both.\n",
    "            if region==\"North\":\n",
    "                condition=90-theta[x]>10\n",
    "            elif region==\"South\":\n",
    "                condition=90-theta[x]<-10\n",
    "            elif region==\"All\":\n",
    "                condition=abs(90-theta[x])>10\n",
    "                \n",
    "            if condition: # We ignore the galactic center: 10>|b|\n",
    "                range_csc=0 #dummy var to index cscb_Temp_values\n",
    "                csc=1/np.sin(abs(np.radians(90-theta[x])))\n",
    "                while range_csc<=9:\n",
    "                    if range_csc/2+1<=csc<range_csc/2+1.5: #append all values within 0.25 csc |b|\n",
    "                        cscb_Temp_values[range_csc].append(File_as_List[x])\n",
    "                        unc_Temp_values[range_csc].append(Unc_as_List[x])\n",
    "                        csc_list[range_csc].append(csc)\n",
    "                        range_csc=range_csc+10\n",
    "                    else:\n",
    "                        range_csc=range_csc+1 #if the entry is not within 1<x<1.5, increase to 1.5<x<2.0 (for 1.75), etc.\n",
    "\n",
    "    Mean_cscb_Temp=[]\n",
    "    Mean_csc_list=[]\n",
    "    cal_Unc_array=[]\n",
    "    cscb_Temp_sigma=[]\n",
    "    ARCADE_arr=[]\n",
    "    num_data_points=0\n",
    "    for i in range(10):\n",
    "        if not cscb_Temp_values[i]==[]: #if there are any values within the range of csc we defined above:\n",
    "            Mean_cscb_Temp.append(np.mean(cscb_Temp_values[i])) # we mean the temperature and create a scatter plot\n",
    "            Mean_csc_list.append(np.mean(csc_list[i])) # we also mean csc\n",
    "            #ARCADE_arr.append(np.sqrt((file[4][0]**2)/len(cscb_Temp_values[i]))) #for replicating the graph in the ARCADE paper\n",
    "            \n",
    "            if file[3]==False:\n",
    "                if type(file[4])==list:\n",
    "                    cscb_stat_sigma.append(file[4][0]/np.sqrt(len(cscb_Temp_values[i]))) #we define stat unc. to use for inflation\n",
    "                    if file[1]==45 and region==\"South\":\n",
    "                        cscb_stat_sigma=(np.array(cscb_Temp_sigma)*2300/300).tolist()\n",
    "                else:\n",
    "                    cscb_Temp_sigma.append(np.sqrt(np.sum(np.array(unc_Temp_values[i])**2/len(unc_Temp_values[i])**2)))\n",
    "            else:\n",
    "                #We convert uncertainty to antenna temp (though to third order they are the same)\n",
    "                IGL=(6.62607015*(10**(-34))*file[1]*(10**6))/(1.380649*(10**(-23))*np.array(cscb_Temp_values[i]))\n",
    "                cscb_Temp_sigma.append(np.sqrt(np.sum((file[4][0]*(IGL**2)*np.exp(IGL)/((np.exp(IGL)-1)**2))**2)/(len(cscb_Temp_values[i]))**2))\n",
    "\n",
    "            cal_Unc_array.append(np.sqrt(np.sum(np.array(unc_Temp_values[i])**2/len(unc_Temp_values[i])**2))) #we define cal uncertainty\n",
    "            num_data_points+=1 \n",
    "    Mean_cscb_Temp = np.array(Mean_cscb_Temp)\n",
    "    \n",
    "    #first we do our fit with only statistical uncertainty\n",
    "    ChiSquared = lambda T: np.sum(((T[0]+T[1]*np.array(Mean_csc_list)-Mean_cscb_Temp)/(cscb_stat_sigma))**2)\n",
    "    bnds = ((0, np.inf),(0, np.inf))\n",
    "    results=minimize(ChiSquared,x0=(np.mean(Mean_cscb_Temp),np.mean(Mean_cscb_Temp)),bounds=bnds)\n",
    "    if results.fun/(num_data_points-2)>=1: #if the results are >1, we inflate the uncertainties until chi^2/dof=1\n",
    "        cscb_stat_sigma=np.array(cscb_stat_sigma)*np.sqrt(results.fun/(num_data_points-2))\n",
    "\n",
    "    if type(file[4])==list:\n",
    "        sgma=np.sqrt(np.array(cscb_stat_sigma)**2+np.array(cal_Unc_array)**2) #we then add calibration error and refit\n",
    "    else:\n",
    "        sgma=cscb_Temp_sigma #the LWA maps do not distinguish between types of uncertainties\n",
    "        \n",
    "    def func(x,a,b):\n",
    "        return a*x+b\n",
    "    p,cov=curve_fit(func, Mean_csc_list, Mean_cscb_Temp,sigma=sgma,absolute_sigma=True)\n",
    "    T_g=p[0]\n",
    "    c=p[1]\n",
    "    T_g_unc,c_unc=np.sqrt(np.diag(cov))\n",
    "    if type(file[4])==list:\n",
    "        c_unc=np.sqrt(c_unc**2)\n",
    "        #Plotting uncertainty:\n",
    "    \"\"\"\n",
    "    #For if we want to produce the graphs in the ARCADE paper\n",
    "    if file[1]==408 or file[1]==3150:\n",
    "        if file[1]==408:\n",
    "            plt.errorbar(x=Mean_csc_list,y=Mean_cscb_Temp,yerr=np.array(ARCADE_arr)*20,fmt=\"none\",color=\"maroon\",capsize=2)\n",
    "            plt.scatter(Mean_csc_list,Mean_cscb_Temp,color=\"red\")\n",
    "            plt.plot(Mean_csc_list,T_g*np.array(Mean_csc_list)+c)\n",
    "            plt.title(\"csc|b| vs Temp at %s MHz\" % file[1])\n",
    "            plt.xlabel(\"csc|b|\")\n",
    "            plt.ylabel(\"Antenna Temp (K)\")\n",
    "            plt.grid()\n",
    "            plt.minorticks_on()\n",
    "            #plt.savefig(\"T_g_408_MHz_ARCADE_Replica_in_Paper\",dpi=200)\n",
    "        if file[1]==3150:\n",
    "            plt.errorbar(x=Mean_csc_list,y=Mean_cscb_Temp,yerr=np.array(ARCADE_arr)*5,fmt=\"none\",color=\"maroon\",capsize=2)\n",
    "            plt.scatter(Mean_csc_list,Mean_cscb_Temp,color=\"red\")\n",
    "            plt.plot(Mean_csc_list,T_g*np.array(Mean_csc_list)+c)\n",
    "            plt.title(\"csc|b| vs Temp at %s MHz\" % file[1])\n",
    "            plt.xlabel(\"csc|b|\")\n",
    "            plt.ylabel(\"Antenna Temp (K)\")\n",
    "            plt.grid()\n",
    "            plt.minorticks_on()\n",
    "            #plt.savefig(\"T_g_3150_MHz_ARCADE_Replica_in_Paper\",dpi=200)\n",
    "        plt.show()\n",
    "    \"\"\"\n",
    "    if graph==True:\n",
    "        #Plotting uncertainty:\n",
    "        plt.errorbar(x=Mean_csc_list,y=Mean_cscb_Temp,yerr=sgma,fmt=\"none\",color=\"maroon\",capsize=2)\n",
    "        #Plotting the scatter:\n",
    "        plt.scatter(Mean_csc_list,Mean_cscb_Temp,color=\"red\")\n",
    "        #Fitting the scatter and plotting:\n",
    "        plt.plot(Mean_csc_list,T_g*np.array(Mean_csc_list)+c)\n",
    "        plt.title(\"csc|b| vs Temp at %s MHz\" % file[1])\n",
    "        plt.xlabel(\"csc|b|\")\n",
    "        plt.ylabel(\"Antenna Temp (K)\")\n",
    "        plt.grid()\n",
    "        plt.show()\n",
    "        print(\"T_extra at %sMHz is %.5f plus/minus %.5f\" % (file[1], c,c_unc))\n",
    "        print(\"T_g at %sMHz is %.5f plus/minus %.5f\" % (file[1],T_g,T_g_unc))\n",
    "    return c,c_unc,T_g,T_g_unc,file[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00a6368c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cscb_Temp_fit_hol(file,region,graph):\n",
    "    \n",
    "    #We first convert the array to a list to go faster\n",
    "    if file[1]==1420:#1420 MHz is the only one on this list (so far) that is in mK\n",
    "        File_as_List=(hp.read_map(file[0])/1000).tolist()\n",
    "    else:\n",
    "        File_as_List=(hp.read_map(file[0])).tolist()\n",
    "\n",
    "    #If we have an uncertainty map, we read it and make it a list\n",
    "    if type(file[4])==str:\n",
    "        Unc_as_List=(hp.read_map(file[4])).tolist()\n",
    "    elif type(file[4])==list:\n",
    "        Unc_as_List=((np.sqrt((0.01*file[4][1]*np.array(File_as_List))**2))+0.000001).tolist()\n",
    "\n",
    "    #If we start in thermo-temp, we make sure to converto to antenna temp:\n",
    "    \n",
    "    if file[3]==True:\n",
    "        convert_to_TA(File_as_List,file[1])\n",
    "        \n",
    "    #Next, we define our theta coords to bin each value by csc|b|, making sure to go to galactic coords\n",
    "    npix=int(np.sqrt(len(File_as_List)/12)) #12*NPix^2=total number of pixels\n",
    "    theta1,phi1=hp.pix2ang(npix,np.arange(len(File_as_List)))\n",
    "    if file[2]==\"E\":\n",
    "        r = hp.rotator.Rotator(coord=['E','G'])\n",
    "        theta=np.degrees(r(theta1,phi1)[0])\n",
    "        phi=np.degrees(r(theta1,phi1)[1])+180 #phi rotates oddly.\n",
    "    if file[2]==\"C\":\n",
    "        r = hp.rotator.Rotator(coord=['C','G'])\n",
    "        theta=np.degrees(r(theta1,phi1)[0])\n",
    "        phi=np.degrees(r(theta1,phi1)[1])+180\n",
    "    if file[2]==\"G\":\n",
    "        theta=np.degrees(theta1)\n",
    "        phi=np.degrees(phi1)\n",
    "    \n",
    "    #Now we calculate csc|b| for each pixel and add it and its temperature to a list\n",
    "    Tempvalues=[]\n",
    "    cscvalues=[]\n",
    "    uncvals=[]\n",
    "    for x in (range(int(len(File_as_List)))):\n",
    "        if File_as_List[x]>0 and math.isnan(File_as_List[x])==False and Unc_as_List[x]>0: #ignore hp.UNSEEN and 0 pixels\n",
    "            if file[1]==2326:\n",
    "                File_as_List[x]+=2.505+0.325*(2326/2000)**(-2.75)\n",
    "            #We may look at the northern hemisphere, southern, or both\n",
    "            if region==\"North\" or region==\"All\":\n",
    "                if 90-theta[x]>10:\n",
    "                    Tempvalues.append(File_as_List[x])\n",
    "                    csc=1/np.sin(np.radians(abs(90-theta[x])))\n",
    "                    cscvalues.append(csc)\n",
    "                    uncvals.append(Unc_as_List[x])\n",
    "            if region==\"South\" or region==\"All\":\n",
    "                if 90-theta[x]<-10:\n",
    "                    Tempvalues.append(File_as_List[x])\n",
    "                    csc=1/np.sin(np.radians(abs(90-theta[x])))\n",
    "                    cscvalues.append(csc)\n",
    "                    uncvals.append(Unc_as_List[x])\n",
    "\n",
    "    #Inflating error bars:\n",
    "    Tempvalues = np.array(Tempvalues)\n",
    "    if type(file[4])==list:\n",
    "        cscb_stat_sigma=0*np.arange(len(Tempvalues))+file[4][0] #n=1 here, so no need to divide by sqrt(n)\n",
    "        if file[3]==True:\n",
    "            #Change to T_A\n",
    "            IGL=(6.62607015*(10**(-34))*file[1]*(10**6))/(1.380649*(10**(-23))*np.array(Tempvalues))\n",
    "            cscb_stat_sigma=file[4][0]*(IGL**2)*np.exp(IGL)/((np.exp(IGL)-1)**2)\n",
    "    if file[3]==False and type(file[4])==list:\n",
    "        if file[1]==45 and region==\"South\":\n",
    "            cscb_Temp_sigma=np.array(cscb_Temp_sigma)+2000\n",
    "        ChiSquared = lambda T: np.sum(((T[0]+T[1]*np.array(cscvalues)-Tempvalues)/(cscb_stat_sigma))**2)\n",
    "        bnds = ((0, np.inf),(0, np.inf))\n",
    "        results=minimize(ChiSquared,x0=(np.mean(Tempvalues),np.mean(Tempvalues)),bounds=bnds)\n",
    "        \n",
    "        if results.fun/(len(Tempvalues)-2)>=1:\n",
    "            cscb_stat_sigma=np.array(cscb_stat_sigma)*np.sqrt(results.fun/(len(Tempvalues)-2))\n",
    "    \n",
    "    if type(file[4])==list:\n",
    "        sgma=np.sqrt(np.array(cscb_stat_sigma)**2+np.array(uncvals)**2)\n",
    "    else:\n",
    "        sgma=uncvals\n",
    "        \n",
    "    def func(x,a,b):\n",
    "        return a*x+b\n",
    "    p,cov=curve_fit(func, cscvalues, Tempvalues,sigma=sgma,absolute_sigma=True)\n",
    "    T_g=p[0]\n",
    "    c=p[1]\n",
    "    T_g_unc,c_unc=np.sqrt(np.diag(cov))\n",
    "    if type(file[4])==list:\n",
    "        c_unc=np.sqrt(c_unc**2+file[4][2]**2)\n",
    "    if graph==True:\n",
    "        if type(file[4])==str:\n",
    "            plt.fill_between(cscvalues, Tempvalues-uncvals, Tempvalues+uncvals,facecolor=\"pink\")\n",
    "        plt.scatter(cscvalues,Tempvalues,s=10,color=\"red\")\n",
    "        plt.plot(cscvalues,T_g*np.array(cscvalues)+c)\n",
    "        plt.title(\"csc|b| vs Temp at %s MHz\" % file[1])\n",
    "        plt.xlabel(\"csc|b|\")\n",
    "        plt.ylabel(\"Antenna Temp (K)\")\n",
    "        plt.grid()\n",
    "        plt.show()\n",
    "        print(\"T_extra at %sMHz is %.5f plus/minus %.5f\" % (file[1], c,c_unc))\n",
    "        print(\"T_g at %sMHz is %.5f plus/minus %.5f\"% (file[1],T_g,T_g_unc))\n",
    "    return c,c_unc,T_g,T_g_unc,file[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5e04784",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cscb_Temp_fit_hol_mean(file,region,graph):\n",
    "\n",
    "    #We first convert the array to a list to go faster\n",
    "    if file[1]==1420:#1420 MHz is the only one on this list (so far) that is in mK\n",
    "        File_as_List=(hp.read_map(file[0])/1000).tolist()\n",
    "    else:\n",
    "        File_as_List=(hp.read_map(file[0])).tolist()\n",
    "        \n",
    "    #If the file has an uncertainty map, we read it, and turn it into a list\n",
    "    if type(file[4])==str:\n",
    "        Unc_as_List=(hp.read_map(file[4])).tolist()\n",
    "    elif type(file[4])==list:\n",
    "        Unc_as_List=(np.sqrt((0.01*file[4][1]*np.array(File_as_List))**2)).tolist()\n",
    "    \n",
    "    #If we start in thermo-temp, we make sure to converto to antenna temp:\n",
    "    if file[3]==True:\n",
    "        convert_to_TA(File_as_List,file[1])\n",
    "        TA_conv_arr=[]\n",
    "        for x in range(len(File_as_List)):\n",
    "            if File_as_List[x]>0:\n",
    "                TA_conv_arr.append(File_as_List[x]/hp.read_map(file[0])[x])\n",
    "        TA_conv_factor=np.mean(TA_conv_arr)\n",
    "        \n",
    "    #Next, we define our theta coords to bin each value by csc|b|, making sure to go to galactic\n",
    "    npix=int(np.sqrt(len(File_as_List)/12)) #12*NPix^2=total number of pixels\n",
    "    theta1,phi1=hp.pix2ang(npix,np.arange(len(File_as_List)))\n",
    "    if file[2]==\"E\":\n",
    "        r = hp.rotator.Rotator(coord=['E','G'])\n",
    "        theta=np.degrees(r(theta1,phi1)[0])\n",
    "        phi=np.degrees(r(theta1,phi1)[1])+180\n",
    "    if file[2]==\"C\":\n",
    "        r = hp.rotator.Rotator(coord=['C','G'])\n",
    "        theta=np.degrees(r(theta1,phi1)[0])\n",
    "        phi=np.degrees(r(theta1,phi1)[1])+180\n",
    "    if file[2]==\"G\":\n",
    "        theta=np.degrees(theta1)\n",
    "        phi=np.degrees(phi1)\n",
    "    \n",
    "    Tempvalues=[]\n",
    "    cscvalues=[]\n",
    "    uncvals=[]\n",
    "    Correction_to_45Mhz_RMS=0\n",
    "    for x in (range(int(len(File_as_List)))): #We start off by doing what we did in the previous method\n",
    "        if File_as_List[x]>0 and math.isnan(File_as_List[x])==False and Unc_as_List[x]>=0: #ignore hp.UNSEEN and 0 pixels   \n",
    "            if file[1]==2326:\n",
    "                File_as_List[x]+=2.505+0.325*(2326/2000)**(-2.75)\n",
    "            if region==\"North\" or region==\"All\":\n",
    "                if 70>90-theta[x]>10:\n",
    "                    Tempvalues.append(File_as_List[x])\n",
    "                    csc=1/np.sin(np.radians(abs(90-theta[x])))\n",
    "                    cscvalues.append(csc) \n",
    "                    uncvals.append(Unc_as_List[x])\n",
    "            if region==\"South\" or region==\"All\":\n",
    "                if -70<90-theta[x]<-10:\n",
    "                    Tempvalues.append(File_as_List[x])\n",
    "                    csc=1/np.sin(np.radians(abs(90-theta[x])))\n",
    "                    cscvalues.append(csc)\n",
    "                    if file[1]==45 and type(file[4])==list and Correction_to_45Mhz_RMS==0: #45 MHz has different north and south rms unc\n",
    "                        Unc_as_List=np.sqrt(np.array(Unc_as_List)**2-300**2+2300**2).tolist()\n",
    "                        Correction_to_45Mhz_RMS=Correction_to_45Mhz_RMS+1\n",
    "                    uncvals.append(Unc_as_List[x])\n",
    "    \n",
    "    Mean_Temp_List=[]\n",
    "    cal_Unc_array=[]\n",
    "    cscb_stat_sigma=[]\n",
    "    \n",
    "    for x in (range(len(cscvalues))):\n",
    "        cscvalues[x]=round(cscvalues[x], 2) #Now we round each csc value to the hundredths\n",
    "    cscset=list(set(cscvalues)) #we define a set of all of the UNIQUE csc values\n",
    "    cscvalues=np.array(cscvalues)\n",
    "    for x in (cscset):\n",
    "        DummyTempList=[]\n",
    "        DummyUncList=[]\n",
    "        indices=np.where(cscvalues==x)[0] #we look at what indices the csc values are equal...\n",
    "        for i in indices:\n",
    "            DummyTempList.append(Tempvalues[i])\n",
    "            DummyUncList.append(uncvals[i])\n",
    "        Mean_Temp_List.append(np.mean(DummyTempList))\n",
    "        if file[3]==False:\n",
    "            if type(file[4])==list:\n",
    "                cscb_stat_sigma.append(file[4][0]/np.sqrt(len(indices)))\n",
    "                if file[1]==45 and region==\"South\":\n",
    "                    cscb_stat_sigma=(np.array(cscb_stat_sigma)*2300/300).tolist()\n",
    "        else:\n",
    "            IGL=(6.62607015*(10**(-34))*file[1]*(10**6))/(1.380649*(10**(-23))*np.array(DummyTempList))\n",
    "            cscb_stat_sigma.append(np.sqrt(np.sum((file[4][0]*(IGL**2)*np.exp(IGL)/((np.exp(IGL)-1)**2))**2)/(len(DummyTempList))**2))\n",
    "        cal_Unc_array.append(np.sqrt(np.sum(np.array(DummyUncList)**2/len(indices)**2)))\n",
    "\n",
    "    #Due to the fill-between function reading cscvalues in order, and yet, they are all jumbled, we have to order\n",
    "    #the csc values and their temps/uncertainties:\n",
    "    Sortedvals=[]\n",
    "    for x in range(len(cscset)):\n",
    "        Sortedvals.append([cscset[x],Mean_Temp_List[x],cal_Unc_array[x]])\n",
    "    Sortedvals=np.array(sorted(Sortedvals)).transpose()\n",
    "    cscset=Sortedvals[0]\n",
    "    Mean_Temp_List=Sortedvals[1]\n",
    "    cal_Unc_array=Sortedvals[2]\n",
    "\n",
    "    #inflate error bars:\n",
    "    if file[3]==False and type(file[4])==list:\n",
    "        if file[1]==45 and region==\"South\":\n",
    "            cscb_stat_sigma=np.array(cscb_stat_sigma)+2000\n",
    "        ChiSquared = lambda T: np.sum(((T[0]+T[1]*np.array(cscset)-Mean_Temp_List)/(cscb_stat_sigma))**2)\n",
    "        bnds = ((0, np.inf),(0, np.inf))\n",
    "        results=minimize(ChiSquared,x0=(np.mean(Mean_Temp_List),np.mean(Mean_Temp_List)),bounds=bnds)\n",
    "        if results.fun/(len(cscset)-2)>=1:\n",
    "            cscb_stat_sigma=np.array(cscb_stat_sigma)*np.sqrt(results.fun/(len(cscset)-2))\n",
    "    \n",
    "    if type(file[4])==list:\n",
    "        sgma=np.sqrt(np.array(cscb_stat_sigma)**2+np.array(cal_Unc_array)**2)\n",
    "    else:\n",
    "        sgma=cal_Unc_array\n",
    "    def func(x,a,b):\n",
    "        return a*x+b\n",
    "    p,cov=curve_fit(func, cscset, Mean_Temp_List,sigma=sgma,absolute_sigma=True)\n",
    "    T_g=p[0]\n",
    "    c=p[1]\n",
    "    T_g_unc,c_unc=np.sqrt(np.diag(cov))\n",
    "    if type(file[4])==list:\n",
    "        c_unc=np.sqrt(c_unc**2+file[4][2]**2)\n",
    "    \n",
    "    if graph==True:\n",
    "        plt.scatter(cscset,Mean_Temp_List,s=3,color=\"red\")\n",
    "        plt.plot(cscset,T_g*np.array(cscset)+c)\n",
    "        plt.title(\"csc|b| vs Temp at %s MHz\" % file[1])\n",
    "        plt.xlabel(\"csc|b|\")\n",
    "        plt.ylabel(\"Antenna Temp (K)\")\n",
    "        plt.grid()\n",
    "        plt.show()\n",
    "        print(\"T_extra at %sMHz is %.5f plus/minus %.5f\" % (file[1], c,c_unc))\n",
    "        print(\"T_g at %sMHz is %.5f plus/minus %.5f\"% (file[1],T_g,T_g_unc))\n",
    "    return c,c_unc,T_g,T_g_unc,file[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab289ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ChiSquaredMinimizer(file,T_g_array,T_g_unc):\n",
    "    if file[1]==1420:#1420 MHz is the only one on this list (so far) that is in mK\n",
    "        Map_as_array=hp.ud_grade((hp.read_map(file[0])/1000),16)\n",
    "    else:\n",
    "        Map_as_array=hp.ud_grade((hp.read_map(file[0])),16)\n",
    "    \n",
    "    nside=int(np.sqrt(len(Map_as_array)/12))\n",
    "    FreeFree_Map=(hp.ud_grade(hp.read_map(\"lambda_fds_dust_94GHz.fits\"),nside)).tolist()\n",
    "    #Synch_Map=hp.ud_grade((hp.read_map(\"wmap_K_mem_synch_9yr_v5.fits\")),nside).tolist()\n",
    "    Synch_Map=hp.ud_grade(hp.ud_grade(hp.read_map(\"haslam408_dsds_Remazeilles2014.fits\"),128)\n",
    "                           -np.array(Rescaled408map)\n",
    "                          ,nside).tolist()\n",
    "    #We convert all maps to TA-- no worries about uncertainty values since they are all the same to order 3\n",
    "    if file[3]==True:\n",
    "        convert_to_TA(Map_as_array,file[1])    \n",
    "    \n",
    "    theta,phi=np.degrees(hp.pix2ang(nside,np.arange(len(Map_as_array))))\n",
    "    \n",
    "    #Here we must rotate as we are subtracting maps\n",
    "    if file[2]==\"E\":\n",
    "        Map_as_array=MAP_Rotation_to_G(Map_as_array,\"E\")\n",
    "    if file[2]==\"C\":\n",
    "        Map_as_array=MAP_Rotation_to_G(Map_as_array,\"C\")\n",
    "    Map_as_array=Map_as_array.tolist()\n",
    "    \n",
    "    Map_cut=[]\n",
    "    Freefree_map_cut=[]\n",
    "    Synch_map_cut=[]\n",
    "    \n",
    "    #We rotate the uncertainty maps as well for the LWAs\n",
    "    if type(file[4])==str:\n",
    "        sigma=[]\n",
    "        sigmaMap=hp.read_map(file[4])\n",
    "        if file[2]==\"E\":\n",
    "            sigmaMap=MAP_Rotation_to_G(sigmaMap,\"E\")\n",
    "        if file[2]==\"C\":\n",
    "            sigmaMap=MAP_Rotation_to_G(sigmaMap,\"C\")\n",
    "        sigmaMap=sigmaMap.tolist()\n",
    "    \n",
    "    #We only use pixels whose temp is >0, outside of |b|<10, and where the synchrotron map behaves properly\n",
    "    for x in range(len(Map_as_array)):\n",
    "        if Map_as_array[x]>0 and math.isnan(Map_as_array[x])==False and abs(90-theta[x])>10 and Synch_Map[x]>=0:\n",
    "            if file[1]==2326:\n",
    "                Map_as_array[x]+=2.505+0.325*(2326/2000)**(-2.75)\n",
    "            if type(file[4])==list:            \n",
    "                Map_cut.append(Map_as_array[x])\n",
    "                Freefree_map_cut.append(FreeFree_Map[x])\n",
    "                Synch_map_cut.append(Synch_Map[x])\n",
    "            if type(file[4])==str and sigmaMap[x]>0:\n",
    "                sigma.append(sigmaMap[x])\n",
    "                Map_cut.append(Map_as_array[x])\n",
    "                Freefree_map_cut.append(FreeFree_Map[x])\n",
    "                Synch_map_cut.append(Synch_Map[x])\n",
    "    if type(file[4])==list:\n",
    "        #we include in our uncertainty RMS and calibration\n",
    "        sigma=(np.sqrt(file[4][0]**2+(0.01*file[4][1]*np.array(Map_cut))**2)).tolist()\n",
    "\n",
    "    #fitting\n",
    "    def loglike(alpha):\n",
    "        return -0.5 * np.sum(((np.array(Map_cut)-alpha[0]-alpha[1]*np.array(Freefree_map_cut)\n",
    "                             -alpha[2]*np.array(Synch_map_cut))/(np.array(sigma)))**2)\n",
    "        \n",
    "    alpha,alpha_err=DynestyFit(3,loglike,[[np.max(Map_cut),-np.max(Map_cut)],[2*np.max(Map_cut),0],[2*np.max(Map_cut),0]],False)\n",
    "    \n",
    "    FreefreedumNorth=[]\n",
    "    SynchdumNorth=[]\n",
    "    FreefreedumSouth=[]\n",
    "    SynchdumSouth=[]\n",
    "    theta_N=[]\n",
    "    theta_S=[]\n",
    "\n",
    "    for x in range(len(Map_as_array)):\n",
    "        if 90-theta[x]>75:\n",
    "            FreefreedumNorth.append(FreeFree_Map[x])\n",
    "            SynchdumNorth.append(Synch_Map[x])\n",
    "            theta_N.append(90-theta[x])\n",
    "        if 90-theta[x]<-75:\n",
    "            FreefreedumSouth.append(FreeFree_Map[x])\n",
    "            SynchdumSouth.append(Synch_Map[x])\n",
    "            theta_S.append(90-theta[x])\n",
    "    \n",
    "    #For north and south we calculate from our formula the uncertainty and T_exc value\n",
    "    theta_N=np.array(theta_N)\n",
    "    theta_S=np.array(theta_S)\n",
    "    \n",
    "    T_g_N=T_g_array[files.index(file)][0]*1/np.sin(np.radians(abs(theta_N)))\n",
    "    \n",
    "    T_ff_N=np.array(FreefreedumNorth)*alpha[1]\n",
    "    T_ff_N_err=np.sqrt((np.mean(FreefreedumNorth)*alpha_err[1])**2+(alpha[1]*np.std(FreefreedumNorth))**2)\n",
    "    T_s_N=np.array(SynchdumNorth)*alpha[2]\n",
    "    T_s_N_err=np.sqrt((np.mean(SynchdumNorth)*alpha_err[2])**2+(alpha[2]*np.std(SynchdumNorth))**2)\n",
    "    \n",
    "    T_exc_N=np.mean(alpha[0]+(T_ff_N+T_s_N-T_g_N))\n",
    "    T_exc_N_err=(np.sqrt(alpha_err[0]**2+(T_ff_N_err**2+T_s_N_err**2+T_g_unc[files.index(file)][0]**2)))\n",
    "\n",
    "    T_g_S=T_g_array[files.index(file)][1]*1/np.sin(np.radians(abs(theta_S)))\n",
    "    \n",
    "    T_ff_S=np.array(FreefreedumSouth)*alpha[1]\n",
    "    T_ff_S_err=np.sqrt((np.mean(FreefreedumSouth)*alpha_err[1])**2+(alpha[1]*np.std(FreefreedumSouth))**2)\n",
    "    T_s_S=np.array(SynchdumSouth)*alpha[2]\n",
    "    T_s_S_err=np.sqrt((np.mean(SynchdumSouth)*alpha_err[2])**2+(alpha[2]*np.std(SynchdumSouth))**2)\n",
    "    T_exc_S=np.mean(alpha[0]+(T_ff_S+T_s_S-T_g_S))\n",
    "    T_exc_S_err=(np.sqrt(alpha_err[0]**2+(T_ff_S_err**2+T_s_S_err**2+T_g_unc[files.index(file)][1]**2)))\n",
    "\n",
    "    #We make sure to convert back to Thermo temp and calculate error properly\n",
    "    T_exc=convert_to_TT([(T_exc_N+T_exc_S)/2],file[1])[0]\n",
    "    if type(file[4])==list:\n",
    "        T_exc_err=np.sqrt((T_exc_N_err**2+T_exc_S_err**2)/4+file[4][2]**2)\n",
    "    else:\n",
    "        T_exc_err=np.sqrt((T_exc_N_err**2+T_exc_S_err**2)/4)\n",
    "\n",
    "    print(\"T_exc at %sMHz is %.5f in the North, %.5f in the South w/ TT mean: %.5f pm %.5f\" % (file[1],T_exc_N,T_exc_S,T_exc,T_exc_err))\n",
    "    return T_exc,T_exc_err,alpha[0],alpha_err[0],alpha[1],alpha_err[1],alpha[2],alpha_err[2],file[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a350458c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ChiSquaredMinimizerHM(file,deg):\n",
    "    #Chi^2 minimizer for Hongwan's Method-- WIP\n",
    "    if file[1]==1420:#1420 MHz is the only one on this list (so far) that is in mK\n",
    "        Map_as_array=(hp.read_map(file[0])/1000)\n",
    "\n",
    "    else:\n",
    "        Map_as_array=hp.read_map(file[0])\n",
    "    \n",
    "    nside=int(np.sqrt(len(Map_as_array)/12))\n",
    "    FreeFree_Map=hp.ud_grade(hp.read_map(\"lambda_fds_dust_94GHz.fits\"),nside).tolist()\n",
    "    #Synch_Map=hp.ud_grade((hp.read_map(\"wmap_K_mem_synch_9yr_v5.fits\")),nside).tolist()\n",
    "    Synch_Map=hp.ud_grade(hp.ud_grade(hp.read_map(\"haslam408_dsds_Remazeilles2014.fits\"),128)\n",
    "                           -np.array(Rescaled408map)\n",
    "                          ,nside).tolist()\n",
    "    \n",
    "    if file[3]==True:\n",
    "        convert_to_TA(Map_as_array,file[1])    \n",
    "    \n",
    "    theta,phi=np.degrees(hp.pix2ang(nside,np.arange(len(Map_as_array))))\n",
    "    if file[2]==\"E\":\n",
    "        Map_as_array=MAP_Rotation_to_G(Map_as_array,\"E\")\n",
    "    if file[2]==\"C\":\n",
    "        Map_as_array=MAP_Rotation_to_G(Map_as_array,\"C\")\n",
    "    Map_as_array=Map_as_array.tolist()\n",
    "    \n",
    "\n",
    "    if type(file[4])==str:\n",
    "        sigma_N=[]\n",
    "        sigma_S=[]\n",
    "        sigmaMap=hp.read_map(file[4])\n",
    "        if file[2]==\"E\":\n",
    "            sigmaMap=MAP_Rotation_to_G(sigmaMap,\"E\")\n",
    "        if file[2]==\"C\":\n",
    "            sigmaMap=MAP_Rotation_to_G(sigmaMap,\"C\")\n",
    "        sigmaMap=sigmaMap.tolist()\n",
    "    \n",
    "    theta_cut_N=[]\n",
    "    Map_cut_N=[]\n",
    "    Freefree_map_cut_N=[]\n",
    "    Synch_map_cut_N=[]\n",
    "    theta_cut_S=[]\n",
    "    Map_cut_S=[]\n",
    "    Freefree_map_cut_S=[]\n",
    "    Synch_map_cut_S=[]\n",
    "    \n",
    "    for x in range(len(Map_as_array)):\n",
    "        if Map_as_array[x]>0 and math.isnan(Map_as_array[x])==False and abs(90-theta[x])>deg and Synch_Map[x]>=0:\n",
    "            if file[1]==2326:\n",
    "                Map_as_array[x]+=2.505+0.325*(2326/2000)**(-2.75)\n",
    "            if 90-theta[x]>0:\n",
    "                if type(file[4])==list:            \n",
    "                    Map_cut_N.append(Map_as_array[x])\n",
    "                    Freefree_map_cut_N.append(FreeFree_Map[x])\n",
    "                    Synch_map_cut_N.append(Synch_Map[x])\n",
    "                    theta_cut_N.append(90-theta[x])\n",
    "                if type(file[4])==str and sigmaMap[x]>0:\n",
    "                    sigma_N.append(sigmaMap[x])\n",
    "                    Map_cut_N.append(Map_as_array[x])\n",
    "                    Freefree_map_cut_N.append(FreeFree_Map[x])\n",
    "                    Synch_map_cut_N.append(Synch_Map[x])\n",
    "                    theta_cut_N.append(90-theta[x])\n",
    "            elif 90-theta[x]<0:\n",
    "                if type(file[4])==list:            \n",
    "                    Map_cut_S.append(Map_as_array[x])\n",
    "                    Freefree_map_cut_S.append(FreeFree_Map[x])\n",
    "                    Synch_map_cut_S.append(Synch_Map[x])\n",
    "                    theta_cut_S.append(90-theta[x])\n",
    "                if type(file[4])==str and sigmaMap[x]>0:\n",
    "                    sigma_S.append(sigmaMap[x])\n",
    "                    Map_cut_S.append(Map_as_array[x])\n",
    "                    Freefree_map_cut_S.append(FreeFree_Map[x])\n",
    "                    Synch_map_cut_S.append(Synch_Map[x])\n",
    "                    theta_cut_S.append(90-theta[x])                    \n",
    "    if type(file[4])==list:\n",
    "        sigma_N=(np.sqrt(file[4][0]**2+(0.01*file[4][1]*np.array(Map_cut_N))**2)).tolist()\n",
    "        sigma_S=(np.sqrt(file[4][0]**2+(0.01*file[4][1]*np.array(Map_cut_S))**2)).tolist()\n",
    "        \n",
    "        \n",
    "    FreefreedumNorth=[]\n",
    "    SynchdumNorth=[]\n",
    "    FreefreedumSouth=[]\n",
    "    SynchdumSouth=[]\n",
    "    cscvals=[]\n",
    "    for x in range(len(Map_as_array)):\n",
    "        if 90-theta[x]>75:\n",
    "            FreefreedumNorth.append(FreeFree_Map[x])\n",
    "            SynchdumNorth.append(Synch_Map[x])\n",
    "            cscvals.append(1/np.sin(np.radians(abs(90-theta[x]))))\n",
    "        if 90-theta[x]<-75:\n",
    "            FreefreedumSouth.append(FreeFree_Map[x])\n",
    "            SynchdumSouth.append(Synch_Map[x])\n",
    "\n",
    "    #alpha[3]=T_g\n",
    "    \n",
    "    ChiSquared = lambda alpha: np.sum((((np.array(Map_cut_N)-alpha[3]*np.mean(cscvals)-alpha[0]\n",
    "                                         -alpha[1]*np.array(Freefree_map_cut_N-np.mean(FreefreedumNorth))\n",
    "                                         -alpha[2]*np.array(Synch_map_cut_N-np.mean(SynchdumNorth)))/(sigma_N))**2))+ np.sum(((\n",
    "        np.array(Map_cut_N)-alpha[3]/np.sin(np.radians(abs(np.array(theta_cut_N))))-alpha[0])/(sigma_N))**2)+np.sum((((\n",
    "        np.array(Map_cut_S)-alpha[4]*np.mean(cscvals)-alpha[5]\n",
    "                                         -alpha[1]*np.array(Freefree_map_cut_S-np.mean(FreefreedumSouth))\n",
    "                                         -alpha[2]*np.array(Synch_map_cut_S-np.mean(SynchdumSouth)))/(sigma_S))**2))+ np.sum(((\n",
    "        np.array(Map_cut_S)-alpha[4]/np.sin(np.radians(abs(np.array(theta_cut_S))))-alpha[5])/(sigma_S))**2)\n",
    "    bnds = ((-np.inf, np.inf),(0, np.inf),(0, np.inf),(-np.inf,np.inf),(-np.inf, np.inf),(-np.inf, np.inf))\n",
    "    maps=minimize(ChiSquared,x0=(np.mean(Map_cut_S),0.1,1,np.mean(Map_cut_S),np.mean(Map_cut_S),np.mean(Map_cut_S)),bounds=bnds)\n",
    "    alpha=maps.x\n",
    "    T_g_N=alpha[3]\n",
    "    T_exc_N=alpha[0]\n",
    "    T_g_S=alpha[4]\n",
    "    T_exc_S=alpha[5]\n",
    "    T_exc=convert_to_TT([(T_exc_N+T_exc_S)/2],file[1])[0]\n",
    "    T_g=convert_to_TT([(T_g_N+T_g_S)/2],file[1])[0]\n",
    "    print(\"T_exc at %sMHz is %.5f in the North, %.5f in the South w/ TT mean: %.5f\" % (file[1],T_exc_N,T_exc_S,T_exc))\n",
    "    print(\"T_G at %sMHz is %.5f in the North, %.5f in the South w/ TT mean: %.5f\" % (file[1],T_g_N,T_g_S,T_g))\n",
    "    print(\"\")\n",
    "    return(alpha[0],alpha[1],alpha[2],T_exc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
