{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import healpy as hp\n",
    "from astropy.io import fits\n",
    "from scipy.optimize import least_squares\n",
    "from tqdm.notebook import tqdm\n",
    "import dynesty\n",
    "from dynesty import utils as dyfunc\n",
    "from multiprocessing import Pool\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#from joblib import Parallel, delayed\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "plt.rcdefaults()\n",
    "from matplotlib import font_manager\n",
    "from matplotlib import rcParams\n",
    "from matplotlib import rc\n",
    "from matplotlib import colors\n",
    "\n",
    "'''rcParams['mathtext.rm'] = 'Computer Modern'\n",
    "rcParams['text.usetex'] = True\n",
    "rcParams['font.family'] = 'serif'\n",
    "\n",
    "font_manager.findfont('serif', rebuild_if_missing=True)\n",
    "fontsize = 14\n",
    "rcParams.update({'font.size' : fontsize})'''\n",
    "\n",
    "#My own files \n",
    "from MyUnits import *\n",
    "from fake_dict import fake_dict\n",
    "\n",
    "HomeDir = './'\n",
    "DataDir = HomeDir + 'template_data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process fake data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## frequencies of maps\n",
    "nu_list = np.asarray(list(fake_dict.keys()))\n",
    "num_maps = len(nu_list)\n",
    "## map properties\n",
    "rms_list = np.asarray([fake_dict.get(f).get('rms') for f in nu_list])\n",
    "calib_list = np.asarray([fake_dict.get(f).get('calib') for f in nu_list])\n",
    "zp_list = np.asarray([fake_dict.get(f).get('zero_pt') for f in nu_list])\n",
    "resol_list = np.asarray([fake_dict.get(f).get('resol') for f in nu_list])\n",
    "## template coefficients for fake data\n",
    "c_synch_list = np.asarray([fake_dict.get(f).get('c_synch') for f in nu_list])\n",
    "c_ff_list = np.asarray([fake_dict.get(f).get('c_ff') for f in nu_list])\n",
    "c_src_list = np.asarray([fake_dict.get(f).get('c_src') for f in nu_list])\n",
    "c_struct_list = np.asarray([fake_dict.get(f).get('c_struct') for f in nu_list])\n",
    "\n",
    "\n",
    "# initial resolution of fake_data\n",
    "i_res = 64 \n",
    "\n",
    "# resolution of fit\n",
    "f_res = 16\n",
    "\n",
    "npix = hp.nside2npix(i_res)\n",
    "f_res_pix = hp.nside2npix(f_res)\n",
    "\n",
    "# nmap x npix array of skymaps\n",
    "skymaps = np.zeros((len(nu_list), npix))\n",
    "pt_maps = np.zeros((len(nu_list), npix)) # treat point source maps separately\n",
    "nanloc = np.zeros((len(nu_list), npix), dtype='bool') # keep track of nan locations\n",
    "inv_cov = np.zeros((len(nu_list), f_res_pix))\n",
    "\n",
    "print(rms_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rid of slice |b| < b_min degrees\n",
    "def remove_sky(skymap, b_min, l_min = 0, is_nest = False):\n",
    "    nside = hp.npix2nside(len(skymap))\n",
    "    skymap_cp = np.copy(skymap)\n",
    "    lon, lat = hp.pix2ang(nside, np.arange(len(skymap_cp)), nest = is_nest, lonlat = True)\n",
    "    skymap_cp[np.abs(lat) < b_min] = np.nan\n",
    "    skymap_cp[lon < l_min] = np.nan\n",
    "    skymap_cp[lon > 360 - l_min] = np.nan\n",
    "    #print(len(skymap_cp[~np.isnan(skymap_cp)]))\n",
    "    return skymap_cp\n",
    "\n",
    "# Brightness temperature of CMB\n",
    "def cmb_bt(freq):\n",
    "    return (2.72548 * Kelvin) *(2 * np.pi * freq/(2.72548 * Kelvin)) /(np.exp(2 * np.pi * freq/(2.72548 * Kelvin))-1)\n",
    "\n",
    "## Masking \n",
    "\n",
    "# minimum latitude and longitudes we consider\n",
    "B_MIN = 10\n",
    "L_MIN = 0\n",
    "\n",
    "# initial resolution of fake_data\n",
    "i_res = 64 \n",
    "\n",
    "# resolution of fit\n",
    "f_res = 16\n",
    "\n",
    "npix = hp.nside2npix(i_res)\n",
    "f_res_pix = hp.nside2npix(f_res)\n",
    "\n",
    "pix_list = np.arange(f_res_pix, dtype = 'float')\n",
    "pix_list = remove_sky(pix_list, B_MIN, L_MIN)\n",
    "pix_list = pix_list[~np.isnan(pix_list)]\n",
    "pix_list = np.asarray(pix_list, dtype = 'int')\n",
    "\n",
    "num_pix_r = len(pix_list[~np.isnan(pix_list)]); pix_list\n",
    "\n",
    "\n",
    "#number of b bins per hemisphere\n",
    "num_b = 2\n",
    "b_bins = np.arange(-90, 90, 180/(num_b))\n",
    "# latitudes\n",
    "_, lat = hp.pix2ang(f_res, pix_list, nest = False, lonlat = True)\n",
    "# b bin assignments\n",
    "b_assgn = np.digitize(lat, bins = b_bins)\n",
    "#b_bins = np.concatenate((b_bins, [90]))\n",
    "b_bins, b_assgn\n",
    "\n",
    "csc_i = 1/np.sin(np.abs(lat) * degree)\n",
    "\n",
    "# load source template \n",
    "\n",
    "pt_src = np.load(DataDir + 'pt_src.npy')\n",
    "vlbi_src = np.load(DataDir + 'vlbi_src_mask.npy')\n",
    "pt_src_dg = hp.ud_grade(pt_src, f_res)\n",
    "vlbi_src_dg = hp.ud_grade(vlbi_src, f_res)\n",
    "\n",
    "nu_ = np.asarray([float(n) for n in nu_list]) / 310.0 # reference frequency is 310 MHz\n",
    "nu_arr = np.broadcast_to(nu_, (len(csc_i),len(nu_list))).T\n",
    "\n",
    "# dimensionality of our problem : 2 + 2 * num_b\n",
    "\n",
    "ndim = 2 + 2 * num_b + 1\n",
    "print ('ndim = ' + str(ndim))\n",
    "\n",
    "\n",
    "def loglike(x):\n",
    "    # extragalactic parameters\n",
    "    T_CMB =  x[0] #2.722\n",
    "    T_E =  x[1] #30.4 #\n",
    "    beta_E = x[2] #-2.58 # \n",
    "    \n",
    "    # galactic parameters\n",
    "    T_G  =  x[3 : (2 + num_b)+1] #np.asarray([9.65,8.06]) #\n",
    "    \n",
    "    beta_G = x[(2 + num_b)+1 : (2 + 2 * num_b)+1] # np.asarray([-2.58, -2.56])#\n",
    "    \n",
    "    # isotropic component\n",
    "    TE_i = T_E * np.ones(num_pix_r) \n",
    "    nu_beta_E = np.power(nu_, beta_E)\n",
    "    TE_i_q = np.outer(nu_beta_E, TE_i)\n",
    "\n",
    "    # galactic component\n",
    "    TG_csc_i = T_G[b_assgn-1] * csc_i\n",
    "    nu_beta_G = np.power(nu_arr, beta_G[b_assgn-1])\n",
    "    TG_i_q = TG_csc_i * nu_beta_G\n",
    "    \n",
    "    # residual array\n",
    "    res_arr = inv_cov_r * (skymaps_r - (T_CMB + TE_i_q + TG_i_q))**2\n",
    "    \n",
    "    # contract over pixel and map indices\n",
    "    return -0.5 * np.einsum('qi->', res_arr)\n",
    "\n",
    "\n",
    "\n",
    "'''def ptform(u):\n",
    "    return scale * u + shift'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in the files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Read in maps\n",
    "\n",
    "for i_f, f in enumerate(nu_list):\n",
    "    # load in real_map, \n",
    "    real_map = np.load(fake_dict.get(f).get('skymap'))\n",
    "    real_map = hp.ud_grade(real_map, i_res, pess=True)\n",
    "    real_map[real_map < 0] = np.nan\n",
    "    nanloc[i_f] = (np.isnan(real_map))\n",
    "\n",
    "    # load fake map components (except)\n",
    "    synch_map = hp.ud_grade(np.load(fake_dict.get(f).get('synch_map')), i_res, pess = True)\n",
    "    ff_map = hp.ud_grade(np.load(fake_dict.get(f).get('ff_map')), i_res, pess = True)\n",
    "    src_map = hp.ud_grade(np.load(fake_dict.get(f).get('src_map')), i_res, pess = True)\n",
    "    struct_map = hp.ud_grade(np.load(fake_dict.get(f).get('struct_map')), i_res, pess = True)\n",
    "\n",
    "    # combine templates, treat point sources separately \n",
    "    data = c_synch_list[i_f] * synch_map + c_ff_list[i_f] * ff_map  + c_struct_list[i_f] * struct_map\n",
    "    pt = c_src_list[i_f] * src_map\n",
    "\n",
    "    skymaps[i_f] = data \n",
    "    pt_maps[i_f] = pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inject signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define injection parameters \n",
    "\n",
    "### Extragalactic temperature(s) at 310 MHz (in K)\n",
    "T_eg_list = np.asarray([300])#np.asarray([10,20, 25,30, 35, 40, 45,50, 55,60, 65,70,80,90])\n",
    "### Spectral index for T_eg\n",
    "beta_eg = -2.58\n",
    "### number of iterations per temperature\n",
    "n_iter = 1\n",
    "\n",
    "means_teg = np.zeros((len(T_eg_list), n_iter))\n",
    "means_beg = np.zeros((len(T_eg_list), n_iter))\n",
    "means_cmb = np.zeros((len(T_eg_list), n_iter))\n",
    "\n",
    "errs_teg = np.zeros((len(T_eg_list), n_iter))\n",
    "errs_beg = np.zeros((len(T_eg_list), n_iter))\n",
    "errs_cmb = np.zeros((len(T_eg_list), n_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instiantiate array with priors\n",
    "\n",
    "scale = np.zeros(ndim) # size of prior\n",
    "shift = np.zeros(ndim) # location of prior\n",
    "\n",
    "scale[0] = 0.01\n",
    "scale[1] = 500\n",
    "scale[2] = 1.5\n",
    "scale[3: (2 + num_b)+1] = 15\n",
    "scale[(2 + num_b)+1 : (2 + 2 * num_b)+1] = 1.5\n",
    "\n",
    "shift[0] = 0\n",
    "shift[1] = 0\n",
    "shift[2] = -3.5\n",
    "shift[3: (2 + num_b)+1] = 0\n",
    "shift[(2 + num_b)+1 : (2 + 2 * num_b)+1] = -3.5\n",
    "\n",
    "def ptform(u):\n",
    "        return scale * u + shift\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_t, T_eg in enumerate(T_eg_list):   \n",
    "    for j in range(n_iter):\n",
    "        \n",
    "        ### Inject temperatures \n",
    "        inj_maps_h = np.outer(nu_**beta_eg, T_eg * np.ones(npix)) # high-res\n",
    "        inj_maps_h = inj_maps_h + skymaps # inject signal \n",
    "\n",
    "        cmb_list = 2.725 * np.ones((len(nu_list), npix))# np.outer(2.725 * np.ones(len(nu_list)), np.ones(npix))\n",
    "        inj_maps_h = inj_maps_h #+ cmb_list # inject CMB\n",
    "\n",
    "        inj_maps = np.zeros((len(nu_list), f_res_pix)) #downgraded maps\n",
    "\n",
    "        ## convolve with error and make inv cov \"matrix\"\n",
    "        for i_f, f in enumerate(nu_list):\n",
    "            ## load map of variances\n",
    "            vars = rms_list[i_f]**2 + (calib_list[i_f] * inj_maps_h[i_f])**2 + zp_list[i_f]**2 # np.load(fake_dict.get(f).get('err_map')) \n",
    "            ### sample from gaussian \n",
    "            inj_maps_h[i_f] = np.random.normal(inj_maps_h[i_f], np.sqrt(vars))\n",
    "            pt_maps[i_f][pt_maps[i_f] > 0] = np.random.normal(pt_maps[i_f][pt_maps[i_f] > 0], \n",
    "                                                    np.sqrt((calib_list[i_f] * pt_maps[i_f][pt_maps[i_f] > 0])**2))\n",
    "\n",
    "            ### smooth with gaussian beam (make fluctuations correlated)\n",
    "            smoothed =  inj_maps_h[i_f] #hp.sphtfunc.smoothing(inj_maps_h[i_f], fwhm = 4 * degree) #\n",
    "            meas_map = smoothed + pt_maps[i_f]\n",
    "            meas_map[nanloc[i_f]] = np.nan # set nans to reflect true map\n",
    "            inj_maps_h[i_f] = meas_map\n",
    "            \n",
    "            inj_maps[i_f] = hp.ud_grade(meas_map, f_res, pess = True)  \n",
    "            inj_maps[i_f][np.isnan(inj_maps[i_f])] = 0\n",
    "            inj_maps[i_f][inj_maps[i_f] < 0] = 0  \n",
    "\n",
    "            vars[vars <= 0] = np.nan\n",
    "            vars = hp.ud_grade(vars, f_res, pess = True)\n",
    "            inv_cov[i_f] = 1/vars\n",
    "            # Important: set incomplete data to 0, NOT np.nan, so we can naturally exclude this from the fit\n",
    "            inv_cov[i_f][np.isnan(inv_cov[i_f])] = 0\n",
    "        # chop up the maps so only 4 quadrants remain\n",
    "        # mask out point sources according to pt_tmpl\n",
    "\n",
    "        for i in range(len(nu_list)):\n",
    "            inj_maps[i] = remove_sky(inj_maps[i], B_MIN, L_MIN)\n",
    "            #skymaps[i][pt_src_dg > 0] = np.nan\n",
    "            #skymaps[i][vlbi_src_dg > 0] = np.nan\n",
    "\n",
    "            inv_cov[i] = remove_sky(inv_cov[i], B_MIN, L_MIN)\n",
    "            #inv_cov[i][pt_src_dg > 0] = np.nan\n",
    "            #inv_cov[i][vlbi_src_dg > 0] = np.nan\n",
    "\n",
    "\n",
    "        #exclude nan vals\n",
    "\n",
    "        skymaps_r = np.zeros((len(nu_list), num_pix_r))\n",
    "        inv_cov_r = np.zeros((len(nu_list), num_pix_r))\n",
    "\n",
    "\n",
    "        for i_f, f in enumerate(nu_list):\n",
    "            skymaps_r[i_f] = inj_maps[i_f][~np.isnan(inj_maps[i_f])]\n",
    "            inv_cov_r[i_f] = inv_cov[i_f][~np.isnan(inv_cov[i_f])]\n",
    "\n",
    "        num_cores = 40\n",
    "        pool = Pool(num_cores)\n",
    "        # \"Dynamic\" nested sampling.\n",
    "        dsampler = dynesty.DynamicNestedSampler(loglike, ptform, ndim, pool = pool, queue_size = num_cores, sample='auto')\n",
    "        dsampler.run_nested(print_progress=False)\n",
    "        results = dsampler.results\n",
    "        \n",
    "        # Extract sampling results.\n",
    "        samples = results.samples  # samples\n",
    "        weights = np.exp(results.logwt - results.logz[-1])  # normalized weights\n",
    "\n",
    "        # Compute 1 sigma error bars\n",
    "        quantiles = [dyfunc.quantile(samps, [0.159,0.5,0.841], weights=weights)\n",
    "                    for samps in samples.T]\n",
    "\n",
    "        # Compute weighted mean and covariance.\n",
    "        mean, cov = dyfunc.mean_and_cov(samples, weights)\n",
    "        print(mean)\n",
    "        means_cmb[i_t][j] = mean[0]\n",
    "        errs_cmb[i_t][j] = max(quantiles[0][2] - quantiles[0][1], quantiles[0][1] - quantiles[0][0])\n",
    "\n",
    "        means_teg[i_t][j] = mean[1]\n",
    "        errs_teg[i_t][j] = max(quantiles[1][2] - quantiles[1][1], quantiles[1][1] - quantiles[1][0])\n",
    "\n",
    "        means_beg[i_t][j] = mean[2]\n",
    "        errs_beg[i_t][j] = max(quantiles[2][2] - quantiles[2][1], quantiles[2][1] - quantiles[2][0])\n",
    "    print(T_eg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means_teg, errs_teg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means_beg, errs_beg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means_cmb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('mean_teg.npy', means_teg)\n",
    "np.save('mean_beg.npy', means_beg)\n",
    "np.save('mean_cmb.npy', means_cmb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('errs_teg.npy', errs_teg)\n",
    "np.save('errs_beg.npy', errs_beg)\n",
    "np.save('errs_cmb.npy', errs_cmb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for plots (variable names need to be changed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Extragalactic temp\n",
    "fig, ax = plt.subplots(1,1,figsize = (8,8), dpi = 150)\n",
    "\n",
    "for i in range(len(means[0,:])):\n",
    "    ax.errorbar(temps, means[:, i], yerr = errs[:,i], marker = '.', ls = 'none', color = 'black')\n",
    "\n",
    "ax.plot([0,1],[0,1], transform=ax.transAxes, color = 'black')\n",
    "plt.xlim([0, 100])\n",
    "plt.ylim([0, 100])\n",
    "ax.set_xlabel(r'Injected $T_{\\mathrm{eg}}$ at 310 MHz [K]')\n",
    "ax.set_ylabel(r'Recovered $T_{\\mathrm{eg}}$ [K]')\n",
    "fig.suptitle(r'\\bf{Signal injected vs. signal recovered} ($\\beta_{\\mathrm{eg}} = -2.58$)', fontsize = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CMB\n",
    "fig, ax = plt.subplots(1,1,figsize = (8,6), dpi = 200)\n",
    "\n",
    "ax.errorbar(temps, mn, yerr = er, ls=  'none', capsize = 3, marker = 'v', color = 'black')\n",
    "plt.fill_between(temps, mn-er, mn+er, alpha = 0.6, color = 'green')\n",
    "\n",
    "#ax.plot(temps, 2.725 * np.)\n",
    "#ax.plot([0,1],[0,1], transform=ax.transAxes, color = 'black')\n",
    "#plt.xlim([0, 100])\n",
    "#plt.ylim([0, 100])\n",
    "ax.set_xlabel(r'Injected $T_{\\mathrm{eg}}$ at 310 MHz [K]')\n",
    "ax.set_ylabel(r'Inferred $T_{\\mathrm{CMB}}$ [K]')\n",
    "fig.suptitle(r'\\bf{Signal injected versus recovered CMB temperature} ($\\beta_{\\mathrm{eg}} = -2.58$)', fontsize = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Extragalactic \n",
    "fig, ax = plt.subplots(1,1,figsize = (8,6), dpi = 150)\n",
    "\n",
    "ax.errorbar(temps, mn, yerr = er, ls=  'none', capsize = 3, marker = 'v', color = 'black')\n",
    "plt.fill_between(temps, mn-er, mn+er, alpha = 0.6, color = 'firebrick')\n",
    "\n",
    "#ax.hlines(-2.58, 0, 90)\n",
    "#ax.plot(temps, 2.725 * np.)\n",
    "#ax.plot([0,1],[0,1], transform=ax.transAxes, color = 'black')\n",
    "#plt.xlim([0, 100])\n",
    "#plt.ylim([0, 100])\n",
    "ax.set_xlabel(r'Injected $T_{\\mathrm{eg}}$ at 310 MHz [K]')\n",
    "ax.set_ylabel(r'Inferred $\\beta_{\\mathrm{eg}}$ [K]')\n",
    "fig.suptitle(r'\\bf{Signal injected versus recovered $\\beta_{\\mathrm{eg}}$ ($\\beta_{\\mathrm{eg}} = -2.58$)', fontsize = 20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
