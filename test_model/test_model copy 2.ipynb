{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import healpy as hp\n",
    "from astropy.io import fits\n",
    "from scipy.optimize import least_squares\n",
    "from tqdm.notebook import tqdm\n",
    "import dynesty\n",
    "from dynesty import utils as dyfunc\n",
    "from multiprocessing import Pool\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#from joblib import Parallel, delayed\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "plt.rcdefaults()\n",
    "from matplotlib import font_manager\n",
    "from matplotlib import rcParams\n",
    "from matplotlib import rc\n",
    "from matplotlib import colors\n",
    "\n",
    "'''rcParams['mathtext.rm'] = 'Computer Modern'\n",
    "rcParams['text.usetex'] = True\n",
    "rcParams['font.family'] = 'serif'\n",
    "\n",
    "font_manager.findfont('serif', rebuild_if_missing=True)\n",
    "fontsize = 14\n",
    "rcParams.update({'font.size' : fontsize})'''\n",
    "\n",
    "#My own files \n",
    "from MyUnits import *\n",
    "from fake_dict import fake_dict\n",
    "\n",
    "HomeDir = './'\n",
    "DataDir = HomeDir + 'template_data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process fake data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.00e+03 9.63e+02 3.00e+02 5.26e+02 3.65e+02 2.08e+02 1.12e+02 1.20e+00\n",
      " 1.70e-02 9.01e-03 7.65e-03]\n"
     ]
    }
   ],
   "source": [
    "## frequencies of maps\n",
    "nu_list = np.asarray(list(fake_dict.keys()))\n",
    "num_maps = len(nu_list)\n",
    "## map properties\n",
    "rms_list = np.asarray([fake_dict.get(f).get('rms') for f in nu_list])\n",
    "calib_list = np.asarray([fake_dict.get(f).get('calib') for f in nu_list])\n",
    "zp_list = np.asarray([fake_dict.get(f).get('zero_pt') for f in nu_list])\n",
    "resol_list = np.asarray([fake_dict.get(f).get('resol') for f in nu_list])\n",
    "## template coefficients for fake data\n",
    "c_synch_list = np.asarray([fake_dict.get(f).get('c_synch') for f in nu_list])\n",
    "c_ff_list = np.asarray([fake_dict.get(f).get('c_ff') for f in nu_list])\n",
    "c_src_list = np.asarray([fake_dict.get(f).get('c_src') for f in nu_list])\n",
    "c_struct_list = np.asarray([fake_dict.get(f).get('c_struct') for f in nu_list])\n",
    "\n",
    "\n",
    "# initial resolution of fake_data\n",
    "i_res = 64 \n",
    "\n",
    "# resolution of fit\n",
    "f_res = 16\n",
    "\n",
    "npix = hp.nside2npix(i_res)\n",
    "f_res_pix = hp.nside2npix(f_res)\n",
    "\n",
    "# nmap x npix array of skymaps\n",
    "skymaps = np.zeros((len(nu_list), npix))\n",
    "pt_maps = np.zeros((len(nu_list), npix)) # treat point source maps separately\n",
    "nanloc = np.zeros((len(nu_list), npix), dtype='bool') # keep track of nan locations\n",
    "inv_cov = np.zeros((len(nu_list), f_res_pix))\n",
    "\n",
    "print(rms_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndim = 7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'def ptform(u):\\n    return scale * u + shift'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get rid of slice |b| < b_min degrees\n",
    "def remove_sky(skymap, b_min, l_min = 0, is_nest = False):\n",
    "    nside = hp.npix2nside(len(skymap))\n",
    "    skymap_cp = np.copy(skymap)\n",
    "    lon, lat = hp.pix2ang(nside, np.arange(len(skymap_cp)), nest = is_nest, lonlat = True)\n",
    "    skymap_cp[np.abs(lat) < b_min] = np.nan\n",
    "    skymap_cp[lon < l_min] = np.nan\n",
    "    skymap_cp[lon > 360 - l_min] = np.nan\n",
    "    #print(len(skymap_cp[~np.isnan(skymap_cp)]))\n",
    "    return skymap_cp\n",
    "\n",
    "# Brightness temperature of CMB\n",
    "def cmb_bt(freq):\n",
    "    return (2.72548 * Kelvin) *(2 * np.pi * freq/(2.72548 * Kelvin)) /(np.exp(2 * np.pi * freq/(2.72548 * Kelvin))-1)\n",
    "\n",
    "## Masking \n",
    "\n",
    "# minimum latitude and longitudes we consider\n",
    "B_MIN = 10\n",
    "L_MIN = 0\n",
    "\n",
    "# initial resolution of fake_data\n",
    "i_res = 64 \n",
    "\n",
    "# resolution of fit\n",
    "f_res = 16\n",
    "\n",
    "npix = hp.nside2npix(i_res)\n",
    "f_res_pix = hp.nside2npix(f_res)\n",
    "\n",
    "pix_list = np.arange(f_res_pix, dtype = 'float')\n",
    "pix_list = remove_sky(pix_list, B_MIN, L_MIN)\n",
    "pix_list = pix_list[~np.isnan(pix_list)]\n",
    "pix_list = np.asarray(pix_list, dtype = 'int')\n",
    "\n",
    "num_pix_r = len(pix_list[~np.isnan(pix_list)]); pix_list\n",
    "\n",
    "\n",
    "#number of b bins per hemisphere\n",
    "num_b = 2\n",
    "b_bins = np.arange(-90, 90, 180/(num_b))\n",
    "# latitudes\n",
    "_, lat = hp.pix2ang(f_res, pix_list, nest = False, lonlat = True)\n",
    "# b bin assignments\n",
    "b_assgn = np.digitize(lat, bins = b_bins)\n",
    "#b_bins = np.concatenate((b_bins, [90]))\n",
    "b_bins, b_assgn\n",
    "\n",
    "csc_i = 1/np.sin(np.abs(lat) * degree)\n",
    "\n",
    "# load source template \n",
    "\n",
    "pt_src = np.load(DataDir + 'pt_src.npy')\n",
    "vlbi_src = np.load(DataDir + 'vlbi_src_mask.npy')\n",
    "pt_src_dg = hp.ud_grade(pt_src, f_res)\n",
    "vlbi_src_dg = hp.ud_grade(vlbi_src, f_res)\n",
    "\n",
    "nu_ = np.asarray([float(n) for n in nu_list]) / 310.0 # reference frequency is 310 MHz\n",
    "nu_arr = np.broadcast_to(nu_, (len(csc_i),len(nu_list))).T\n",
    "\n",
    "# dimensionality of our problem : 2 + 2 * num_b\n",
    "\n",
    "ndim = 2 + 2 * num_b + 1\n",
    "print ('ndim = ' + str(ndim))\n",
    "\n",
    "\n",
    "def loglike(x):\n",
    "    # extragalactic parameters\n",
    "    T_CMB =  x[0] #2.722\n",
    "    T_E =  x[1] #30.4 #\n",
    "    beta_E = x[2] #-2.58 # \n",
    "    \n",
    "    # galactic parameters\n",
    "    T_G  =  x[3 : (2 + num_b)+1] #np.asarray([9.65,8.06]) #\n",
    "    \n",
    "    beta_G = x[(2 + num_b)+1 : (2 + 2 * num_b)+1] # np.asarray([-2.58, -2.56])#\n",
    "    \n",
    "    # isotropic component\n",
    "    TE_i = T_E * np.ones(num_pix_r) \n",
    "    nu_beta_E = np.power(nu_, beta_E)\n",
    "    TE_i_q = np.outer(nu_beta_E, TE_i)\n",
    "\n",
    "    # galactic component\n",
    "    TG_csc_i = T_G[b_assgn-1] * csc_i\n",
    "    nu_beta_G = np.power(nu_arr, beta_G[b_assgn-1])\n",
    "    TG_i_q = TG_csc_i * nu_beta_G\n",
    "    \n",
    "    # residual array\n",
    "    res_arr = inv_cov_r * (skymaps_r - (T_CMB + TE_i_q + TG_i_q))**2\n",
    "    \n",
    "    # contract over pixel and map indices\n",
    "    return -0.5 * np.einsum('qi->', res_arr)\n",
    "\n",
    "\n",
    "\n",
    "'''def ptform(u):\n",
    "    return scale * u + shift'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in the files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Read in maps\n",
    "\n",
    "for i_f, f in enumerate(nu_list):\n",
    "    # load in real_map, \n",
    "    real_map = np.load(fake_dict.get(f).get('skymap'))\n",
    "    real_map = hp.ud_grade(real_map, i_res, pess=True)\n",
    "    real_map[real_map < 0] = np.nan\n",
    "    nanloc[i_f] = (np.isnan(real_map))\n",
    "\n",
    "    # load fake map components (except)\n",
    "    synch_map = hp.ud_grade(np.load(fake_dict.get(f).get('synch_map')), i_res, pess = True)\n",
    "    ff_map = hp.ud_grade(np.load(fake_dict.get(f).get('ff_map')), i_res, pess = True)\n",
    "    src_map = hp.ud_grade(np.load(fake_dict.get(f).get('src_map')), i_res, pess = True)\n",
    "    struct_map = hp.ud_grade(np.load(fake_dict.get(f).get('struct_map')), i_res, pess = True)\n",
    "\n",
    "    # combine templates, treat point sources separately \n",
    "    data = c_synch_list[i_f] * synch_map + c_ff_list[i_f] * ff_map  + c_struct_list[i_f] * struct_map\n",
    "    pt = c_src_list[i_f] * src_map\n",
    "\n",
    "    skymaps[i_f] = data \n",
    "    pt_maps[i_f] = pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inject signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define injection parameters \n",
    "\n",
    "### Extragalactic temperature(s) at 310 MHz (in K)\n",
    "T_eg_list = np.asarray([50])#np.asarray([10,20, 25,30, 35, 40, 45,50, 55,60, 65,70,80,90])\n",
    "### Spectral index for T_eg\n",
    "beta_eg = -2.58\n",
    "### number of iterations per temperature\n",
    "n_iter = 1\n",
    "\n",
    "means_teg = np.zeros((len(T_eg_list), n_iter))\n",
    "means_beg = np.zeros((len(T_eg_list), n_iter))\n",
    "means_cmb = np.zeros((len(T_eg_list), n_iter))\n",
    "\n",
    "errs_teg = np.zeros((len(T_eg_list), n_iter))\n",
    "errs_beg = np.zeros((len(T_eg_list), n_iter))\n",
    "errs_cmb = np.zeros((len(T_eg_list), n_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = np.zeros(ndim) # size of prior\n",
    "shift = np.zeros(ndim) # location of prior\n",
    "\n",
    "scale[0] = 0.0025\n",
    "scale[1] = 70\n",
    "scale[2] = 0.3\n",
    "scale[3: (2 + num_b)+1] = 0.0025\n",
    "scale[(2 + num_b)+1 : (2 + 2 * num_b)+1] = 0.0025\n",
    "\n",
    "shift[0] = -0.0125\n",
    "shift[1] = 0\n",
    "shift[2] = -2.7\n",
    "shift[3: (2 + num_b)+1] = -0.00125\n",
    "shift[(2 + num_b)+1 : (2 + 2 * num_b)+1] = -0.00125\n",
    "\n",
    "def ptform(u):\n",
    "        return scale * u + shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20962it [02:18, 65.42it/s, batch: 0 | bound: 277 | nc: 100 | ncall: 228473 | eff(%):  9.155 | loglstar:   -inf < -217724.711 <    inf | logz: -217766.423 +/-  0.283 | dlogz:  6.216 >  0.010] "
     ]
    }
   ],
   "source": [
    "T_eg = T_eg_list[0]\n",
    "j = 0\n",
    "\n",
    "### Inject temperatures \n",
    "inj_maps_h = np.outer(nu_**beta_eg, T_eg * np.ones(npix)) # high-res\n",
    "inj_maps_h = inj_maps_h #+ skymaps # inject signal \n",
    "\n",
    "cmb_list = 2.725 * np.ones(npix) #np.outer(np.asarray([cmb_bt(float(f) * MHz) / Kelvin for f in nu_list]), np.ones(npix))\n",
    "inj_maps_h = inj_maps_h #+ cmb_list # inject CMB\n",
    "\n",
    "inj_maps = np.zeros((len(nu_list), f_res_pix)) #downgraded maps\n",
    "\n",
    "## convolve with error and make inv cov \"matrix\"\n",
    "for i_f, f in enumerate(nu_list):\n",
    "    ## load map of variances\n",
    "    vars = rms_list[i_f]**2 + (calib_list[i_f] * inj_maps_h[i_f])**2 + zp_list[i_f]**2 # np.load(fake_dict.get(f).get('err_map')) \n",
    "    ### sample from gaussian \n",
    "    inj_maps_h[i_f] = np.random.normal(inj_maps_h[i_f], np.sqrt(vars))\n",
    "    pt_maps[i_f][pt_maps[i_f] > 0] = np.random.normal(pt_maps[i_f][pt_maps[i_f] > 0], \n",
    "                                            np.sqrt((calib_list[i_f] * pt_maps[i_f][pt_maps[i_f] > 0])**2))\n",
    "\n",
    "    ### smooth with gaussian beam (make fluctuations correlated)\n",
    "    smoothed = inj_maps_h[i_f] #hp.sphtfunc.smoothing(inj_maps_h[i_f], fwhm = 4 * degree)\n",
    "    meas_map = smoothed + pt_maps[i_f]\n",
    "    meas_map[nanloc[i_f]] = np.nan # set nans to reflect true map\n",
    "    inj_maps_h[i_f] = meas_map\n",
    "    \n",
    "    inj_maps[i_f] = hp.ud_grade(meas_map, f_res, pess = True)  \n",
    "    inj_maps[i_f][np.isnan(inj_maps[i_f])] = 0\n",
    "    inj_maps[i_f][inj_maps[i_f] < 0] = 0  \n",
    "\n",
    "    vars[vars <= 0] = np.nan\n",
    "    vars = hp.ud_grade(vars, f_res, pess = True)\n",
    "    inv_cov[i_f] = 1/vars\n",
    "    # Important: set incomplete data to 0, NOT np.nan, so we can naturally exclude this from the fit\n",
    "    inv_cov[i_f][np.isnan(inv_cov[i_f])] = 0\n",
    "# chop up the maps so only 4 quadrants remain\n",
    "# mask out point sources according to pt_tmpl\n",
    "\n",
    "for i in range(len(nu_list)):\n",
    "    inj_maps[i] = remove_sky(inj_maps[i], B_MIN, L_MIN)\n",
    "    #skymaps[i][pt_src_dg > 0] = np.nan\n",
    "    #skymaps[i][vlbi_src_dg > 0] = np.nan\n",
    "\n",
    "    inv_cov[i] = remove_sky(inv_cov[i], B_MIN, L_MIN)\n",
    "    #inv_cov[i][pt_src_dg > 0] = np.nan\n",
    "    #inv_cov[i][vlbi_src_dg > 0] = np.nan\n",
    "\n",
    "\n",
    "#exclude nan vals\n",
    "\n",
    "skymaps_r = np.zeros((len(nu_list), num_pix_r))\n",
    "inv_cov_r = np.zeros((len(nu_list), num_pix_r))\n",
    "\n",
    "\n",
    "for i_f, f in enumerate(nu_list):\n",
    "    skymaps_r[i_f] = inj_maps[i_f][~np.isnan(inj_maps[i_f])]\n",
    "    inv_cov_r[i_f] = inv_cov[i_f][~np.isnan(inv_cov[i_f])]\n",
    "\n",
    "num_cores = 40\n",
    "pool = Pool(num_cores)\n",
    "# \"Dynamic\" nested sampling.\n",
    "dsampler = dynesty.DynamicNestedSampler(loglike, ptform, ndim, pool = pool, queue_size = num_cores, sample='auto')\n",
    "dsampler.run_nested(print_progress=True)\n",
    "results = dsampler.results\n",
    "\n",
    "# Extract sampling results.\n",
    "samples = results.samples  # samples\n",
    "weights = np.exp(results.logwt - results.logz[-1])  # normalized weights\n",
    "\n",
    "# Compute 1 sigma error bars\n",
    "quantiles = [dyfunc.quantile(samps, [0.159,0.5,0.841], weights=weights)\n",
    "            for samps in samples.T]\n",
    "\n",
    "# Compute weighted mean and covariance.\n",
    "mean, cov = dyfunc.mean_and_cov(samples, weights)\n",
    "print(mean)\n",
    "\n",
    "means_cmb[i_t][j] = mean[0]\n",
    "errs_cmb[i_t][j] = max(quantiles[0][2] - quantiles[0][1], quantiles[0][1] - quantiles[0][0])\n",
    "\n",
    "means_teg[i_t][j] = mean[1]\n",
    "errs_teg[i_t][j] = max(quantiles[1][2] - quantiles[1][1], quantiles[1][1] - quantiles[1][0])\n",
    "\n",
    "means_beg[i_t][j] = mean[2]\n",
    "errs_beg[i_t][j] = max(quantiles[2][2] - quantiles[2][1], quantiles[2][1] - quantiles[2][0])\n",
    "print(T_eg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[45.00028184]]), array([[0.00032383]]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means_teg, errs_teg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-2.47999782]]), array([[2.45275647e-06]]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means_beg, errs_beg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.08991328e-07]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means_cmb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('mean_teg.npy', means_teg)\n",
    "np.save('mean_beg.npy', means_beg)\n",
    "np.save('mean_cmb.npy', means_cmb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('errs_teg.npy', errs_teg)\n",
    "np.save('errs_beg.npy', errs_beg)\n",
    "np.save('errs_cmb.npy', errs_cmb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
